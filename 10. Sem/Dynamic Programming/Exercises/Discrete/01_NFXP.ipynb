{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# magics: ensures that any changes to the modules loaded below will be re-loaded automatically\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext line_profiler\n",
    "\n",
    "# load general packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load modules related to this exercise\n",
    "from model_zucher import zurcher\n",
    "from Solve_NFXP import solve_NFXP\n",
    "import estimate_NFXP as estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before solving the exercise, you should download line_profiler. Line_profiler is a tool to check the performance of our code. To install line_profiler, you can open anaconda prompt and write \"pip install line-profiler\" (without the \" \" of course). If you want to know more about line_profiler, check the link below:\n",
    "\n",
    "https://github.com/rkern/line_profiler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consider the engine replacement model given by:\n",
    "\n",
    "$$\n",
    "V(x,\\varepsilon) = \\max_{d\\in \\{0,1\\}} \\big\\{ u(x,d) + \\varepsilon_d + \\beta\n",
    "\\underbrace{\\int_{X} \\int_{\\Omega} V(x',\\varepsilon') \\pi(x'|x,d) q(\\varepsilon'|x') dx' d\\varepsilon' }_{EV(x,d)} \\big\\}\n",
    "$$\n",
    "\n",
    "Where $ \\varepsilon $ is extreme value Type I distribued and utility is given by:\n",
    "\n",
    "$$\n",
    "u(x,d)=\\left \\{\n",
    "\\begin{array}{ll}\n",
    "    -RC-c(0,\\theta_1) & \\text{if }d=\\text{replace}=1 \\\\\n",
    "    -c(x,\\theta_1) & \\text{if }d=\\text{keep}=0\n",
    "\\end{array} \\right.\n",
    "$$\n",
    "\n",
    "Here\n",
    "\n",
    "- $ RC $ = replacement cost  \n",
    "- $ c(x,\\theta_1) $ = cost of maintenance with preference parameters $ \\theta_1 $  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Look at ReadMe.txt to get an overview of the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Invistigate how the code works, that is ensure you understand:\n",
    "<il type =\"a\">\n",
    "<li> zurcher.init</li>\n",
    "<li> zurcher.setup</li>\n",
    "<li> zurcher.create_grid</li>\n",
    "<li> zucher.state_transition </li>\n",
    "<li> zucher.bellman </li>\n",
    "\n",
    "You can see how they are called below\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Run the code below and make sure you understand what we are printing. \n",
    "What does the last transition probability in each row (equal to 0.05) come from?\n",
    "- This comes from the fact that $p$ must sum to one and since 0.65+0.2+0.1=0.95. Therefore, we are lacking 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model grid:\n",
      " [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "Transition probabilities conditional on not replacing:\n",
      " [[0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.65 0.2  0.1  0.05 0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.65 0.2  0.1  0.05 0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.65 0.2  0.1  0.05 0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.65 0.2  0.1  0.05 0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.65 0.2  0.1  0.05]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.65 0.2  0.15]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.65 0.35]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.  ]]\n",
      "Transition probabilities conditional on replacing:\n",
      " [[0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]]\n",
      "Bellman one run:\n",
      " [0.47407698 0.47254913 0.47102269 0.46949766 0.46797406 0.46645188\n",
      " 0.46493112 0.46341178 0.46189387 0.46037738 0.45886231 0.45734867]\n"
     ]
    }
   ],
   "source": [
    "do_settings = {\n",
    "    'RC': 0.5,\n",
    "    'n': 12,\n",
    "    'p':[0.65,0.2,0.1]   \n",
    "}\n",
    "model = zurcher(**do_settings)\n",
    "\n",
    "print('Model grid:\\n',model.grid)\n",
    "print('Transition probabilities conditional on not replacing:\\n',model.P1)\n",
    "print('Transition probabilities conditional on replacing:\\n',model.P2)\n",
    "ev,pk, dev = model.bellman(np.zeros((model.n)),output=3)\n",
    "print('Bellman one run:\\n',ev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Newton's Method\n",
    "\n",
    "Next, we need to solve the model. Rust 1987 uses Newton–Kantorovich (NK) theorem to solve the Bellman equation in the engine replacement model. To understand the NK algorithm, consider using the Newton's method to solve the single-variable equation, $f(x)=0$. The Newton method uses the iterative procedure stated below to solve the equation:\n",
    "\n",
    "$$x_{n+1} = x_{n} - \\frac{f(x_n)}{f'(x_n)}$$\n",
    "\n",
    "### 4. Use the Newton's Method to solve the equation below. Fill in the Newton step. Try to vary the starting value and see if the solution changes.\n",
    "\n",
    "\n",
    "$$f(x) = 3x^2 - exp(x)=0$$\n",
    "\n",
    "$$f'(x) = g(x) = 6x-exp(x) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root of f(x): 3.73\n",
      "Number of iterations to archieve convergence: 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = lambda x: 3*x**2-np.exp(x)\n",
    "g = lambda x: 6*x-np.exp(x)\n",
    "\n",
    "def newton(f, g, x0, tol=10e-5, max_iter=100):\n",
    "    delta = 2000\n",
    "    it=0\n",
    "    while (max_iter>= it and tol<delta):\n",
    "        x1 = x0- f(x0)/g(x0)\n",
    "        delta = abs(x1-x0)\n",
    "        it += 1\n",
    "        x0 = x1\n",
    "    return x1, it\n",
    "\n",
    "\n",
    "x0,it = newton(f = f, g = g, x0 = 5)\n",
    "\n",
    "x = np.linspace(-2, 4, num=100)\n",
    "fx = f(x)\n",
    "plt.plot(x, fx)\n",
    "plt.axhline(y=0, color='r', linestyle='-')\n",
    "\n",
    "print('Root of f(x):', round(x0,2))\n",
    "print('Number of iterations to archieve convergence:', it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Newton-Kantorovich\n",
    "\n",
    "Now consider solving the engine replacement model. To do so, we need to find the expected value function that solves the Bellman equation.\n",
    "\n",
    "$$\n",
    "EV(x,d) =  \\Gamma(EV)(x,d) \\quad\\Leftrightarrow\\quad (I - \\Gamma)(EV)(x,d)=\\mathbb{0}\n",
    "$$\n",
    "\n",
    "Similar to the Newton iteration, the **NK iteration** uses the following equation\n",
    "\n",
    "$$\n",
    "EV_{k+1} = EV_{k} - (I-\\Gamma')^{-1} (I-\\Gamma)(EV_k)\n",
    "$$\n",
    "\n",
    "- The new operator is the difference between the identity operator \\$I\\$ and Bellman operator $ \\Gamma  $  \n",
    "- $ \\mathbb{0} $ is zero function  \n",
    "- $ I-\\Gamma' $ is a Fréchet derivative of the operator $ I-\\Gamma $  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Solve the model. In order to solve the model, you should understand:\n",
    "<li> solve_NFXP.init</li>\n",
    "<li> solve_NFXP.setup</li>\n",
    "<li> solve_NFXP.poly </li>\n",
    "<li> solve_NFXP.sa </li>\n",
    "<li> solve_NFXP.nk </li>\n",
    "</il>\n",
    "You can see how they are called below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin contraction iterations (for the 1 time)\n",
      "Iteration 1, tol     0.4273, tol(j)/tol(j-1)        nan\n",
      "Iteration 2, tol     0.4272, tol(j)/tol(j-1)        nan\n",
      "Iteration 3, tol     0.4272, tol(j)/tol(j-1)        nan\n",
      "Iteration 4, tol     0.4271, tol(j)/tol(j-1)        nan\n",
      "Iteration 5, tol     0.4271, tol(j)/tol(j-1)        nan\n",
      "Iteration 6, tol      0.427, tol(j)/tol(j-1)        nan\n",
      "Iteration 7, tol     0.4269, tol(j)/tol(j-1)        nan\n",
      "Iteration 8, tol     0.4268, tol(j)/tol(j-1)        nan\n",
      "Iteration 9, tol     0.4266, tol(j)/tol(j-1)        nan\n",
      "Iteration 10, tol     0.4264, tol(j)/tol(j-1)        nan\n",
      "Iteration 11, tol     0.4262, tol(j)/tol(j-1)     0.9994\n",
      "SA stopped prematurely due to relative tolerance. Start NK iterations\n",
      "Elapsed time 0.0256 seconds\n",
      "Begin Newton-Kantorovich iterations (for the 1 time)\n",
      "Iteration 1, tol      13.17, tol(j)/tol(j-1)          1\n",
      "Iteration 2, tol      0.308, tol(j)/tol(j-1)    0.02339\n",
      "Iteration 3, tol    0.08956, tol(j)/tol(j-1)     0.2907\n",
      "Iteration 4, tol   0.003309, tol(j)/tol(j-1)    0.03695\n",
      "Iteration 5, tol  1.158e-05, tol(j)/tol(j-1)   0.003499\n",
      "Iteration 6, tol  2.838e-10, tol(j)/tol(j-1)  2.451e-05\n",
      "N-K converged after 6 iterations, tolerance: 2.838e-10\n",
      "Elapsed time 0.0106 seconds\n",
      "Convergence achieved!\n",
      "Elapsed time: 0.0370 (seconds)\n"
     ]
    }
   ],
   "source": [
    "algorithm = 'poly'\n",
    "do_settings_solver = {\n",
    "    'sa_min': 10,\n",
    "    'sa_max': 1000000,  \n",
    "    'printfxp': 2\n",
    "}\n",
    "\n",
    "solver = solve_NFXP(**do_settings_solver)\n",
    "model = zurcher()\n",
    "\n",
    "ev0 = np.zeros((model.n)) # Initial guess\n",
    "if algorithm == 'sa':\n",
    "    ev = solver.sa(model.bellman, ev0)\n",
    "elif algorithm == 'poly':\n",
    "    ev = solver.poly(model.bellman, ev0, beta = model.beta)\n",
    "else:\n",
    "    print('Algorithm must be \"sa\" or \"poly\"')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Now we have to estimate the model. In order to estimate the model, you should understand:\n",
    "<il type =\"a\">\n",
    "<li> zurcher.read_busdata </li>\n",
    "<li> estimate_NFXP.estimate  </li>\n",
    "<li> estimate_NFXP.ll  </li>\n",
    "</il>\n",
    "\n",
    "You can see how they are called below:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Estimate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structual estimation using busdata from Rust(1987)\n",
      "Beta        = 0.9999\n",
      "n           = 175\n",
      "Sample size = 8156\n",
      " \n",
      "\n",
      "Parameters     Estimates    s.e. \n",
      "RC             9.7689     1.2264 \n",
      "c              1.3427     0.3153 \n",
      " \n",
      "p(1)           0.1069     0.0035  \n",
      "p(2)           0.5154     0.0059  \n",
      "p(3)           0.3621     0.0055  \n",
      "p(4)           0.0143     0.0013  \n",
      "\n",
      "Log-likelihood -8599.86\n",
      "runtime (seconds) 2.0332\n",
      "The model converged: True\n"
     ]
    }
   ],
   "source": [
    "# Set up the model\n",
    "model = zurcher()\n",
    "\n",
    "# Set-up solver\n",
    "solver = solve_NFXP()\n",
    "\n",
    "# Read the data\n",
    "data = model.read_busdata(bustypes=[1,2,3,4])\n",
    "samplesize = data.shape[0]\n",
    "\n",
    "# Estimate the model\n",
    "import time\n",
    "t0 = time.time()\n",
    "theta0 = [0,0]\n",
    "\n",
    "# args for nfxp estimate\n",
    "nfxp_model, optim_res, pnames, theta_hat, Avar, converged=estimate.estimate(model, solver,data,theta0=theta0, twostep=0)\n",
    "\n",
    "t1 = time.time()\n",
    "time = t1-t0\n",
    "\n",
    "# Print the result\n",
    "print(f'Structual estimation using busdata from Rust(1987)')\n",
    "print(f'Beta        = {model.beta:.4f}')\n",
    "print(f'n           = {model.n}')\n",
    "print(f'Sample size = {samplesize}\\n \\n')\n",
    "\n",
    "print(f'Parameters     Estimates    s.e. ') \n",
    "print(f'{pnames[0]}             {theta_hat[0]:.4f}     {np.sqrt(Avar[0,0]):.4f} ')\n",
    "print(f'{pnames[1]}              {theta_hat[1]:.4f}     {np.sqrt(Avar[1,1]):.4f} \\n ')\n",
    "print(f'{pnames[2]}(1)           {theta_hat[2]:.4f}     {np.sqrt(Avar[2,2]):.4f}  ')\n",
    "print(f'{pnames[2]}(2)           {theta_hat[3]:.4f}     {np.sqrt(Avar[3,3]):.4f}  ')\n",
    "print(f'{pnames[2]}(3)           {theta_hat[4]:.4f}     {np.sqrt(Avar[4,4]):.4f}  ')\n",
    "print(f'{pnames[2]}(4)           {theta_hat[5]:.4f}     {np.sqrt(Avar[5,5]):.4f}  \\n')\n",
    "\n",
    "\n",
    "print(f'Log-likelihood {-optim_res.fun*samplesize:.2f}') \n",
    "print(f'runtime (seconds) {time:.4f}')\n",
    "print(f'The model converged: {converged}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        d    x  dx1\n",
      "1     0.0    2    1\n",
      "2     0.0    3    1\n",
      "3     0.0    5    2\n",
      "4     0.0    7    2\n",
      "5     0.0    9    2\n",
      "...   ...  ...  ...\n",
      "8255  0.0  133    0\n",
      "8256  0.0  134    1\n",
      "8257  0.0  135    1\n",
      "8258  0.0  136    1\n",
      "8259  0.0  136    0\n",
      "\n",
      "[8156 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Try using line_profiler in python. This gives you a lot of information about the performance of your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 10.3472 s\n",
      "File: /Users/jvander/Documents/Dynamic-Programming/Exercises/Discrete/estimate_NFXP.py\n",
      "Function: estimate at line 9\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     9                                           def estimate(model,solver,data,theta0=[0,0],twostep=0):\n",
      "    10                                               \"\"\"\" Estimate model using NFXP\"\"\"\n",
      "    11                                               global ev\n",
      "    12         1    2615000.0    3e+06      0.0      ev = np.zeros((model.n)) \n",
      "    13                                               \n",
      "    14         1    1005000.0    1e+06      0.0      samplesize = data.shape[0]\n",
      "    15                                               \n",
      "    16                                               # STEP 1: Find p non-parametrically\n",
      "    17         1   14702000.0    1e+07      0.1      tabulate = data.dx1.value_counts() # Count number of observations for each dx1\n",
      "    18         5    2055000.0 411000.0      0.0      p = [tabulate[i]/sum(tabulate) if i < len(tabulate) else 0 for i in range(len(model.p))]\n",
      "    19                                           \n",
      "    20                                               # STEP 2: Estimate structual parameters\n",
      "    21         1     420000.0 420000.0      0.0      model.p[:] = p # Use first step estimates as starting values for p\n",
      "    22                                               \n",
      "    23                                               # Estimate RC and C\n",
      "    24         1       1000.0   1000.0      0.0      pnames = ['RC','c']\n",
      "    25                                               \n",
      "    26                                               # Call BHHH optimizer\n",
      "    27         1 7269639000.0    7e+09     70.3      res = optimize.minimize(ll,theta0,args = (model, solver, data, pnames), method = 'trust-ncg',jac = grad, hess = hes, tol=1e-8)\n",
      "    28                                               # Update parameters\n",
      "    29         1      17000.0  17000.0      0.0      model = updatepar(model,pnames,res.x)\n",
      "    30                                               \n",
      "    31                                               # Estimate RC, c and p\n",
      "    32         1          0.0      0.0      0.0      if twostep == 0:\n",
      "    33         1          0.0      0.0      0.0          pnames = ['RC','c','p']\n",
      "    34         1       3000.0   3000.0      0.0          theta0 = [model.RC, model.c] + model.p.tolist() # Starting values\n",
      "    35                                                   # Call BHHH optimizer\n",
      "    36         1 3035551000.0    3e+09     29.3          res = optimize.minimize(ll,theta0, args = (model,solver,data, pnames), method = 'trust-ncg',jac = grad, hess = hes, tol = 1e-8)\n",
      "    37                                           \n",
      "    38                                                   # Update parameters\n",
      "    39         1      18000.0  18000.0      0.0          model=updatepar(model,pnames,res.x)\n",
      "    40                                           \n",
      "    41                                               # Converged: \"trust-ncg tends to be very conservative about convergence, and will often return status 2 even when the solution is good.\"\n",
      "    42         1       3000.0   3000.0      0.0      converged   =   (res.status == 2 or res.status ==0)\n",
      "    43                                           \n",
      "    44                                               # Compute Variance-Covaiance matrix\n",
      "    45         1   21175000.0    2e+07      0.2      h = hes(res.x, model, solver,data, pnames) # Hessian\n",
      "    46         1      31000.0  31000.0      0.0      Avar = np.linalg.inv(h*samplesize) # Variance-Covariance matrix from information matrix equality\n",
      "    47                                           \n",
      "    48         1       3000.0   3000.0      0.0      theta_hat = res.x # unpack estimates\n",
      "    49                                               \n",
      "    50         1       3000.0   3000.0      0.0      return model, res, pnames, theta_hat, Avar, converged\n",
      "\n",
      "Total time: 9.91572 s\n",
      "File: /Users/jvander/Documents/Dynamic-Programming/Exercises/Discrete/estimate_NFXP.py\n",
      "Function: ll at line 52\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    52                                           def ll(theta, model, solver,data, pnames, out=1, no_guess = False): # out=1 solve optimization\n",
      "    53                                               \"\"\" Compute log-likelihood function \"\"\"\n",
      "    54                                               global ev # Use global variable to store value function to use as starting value for next iteration\n",
      "    55                                               \n",
      "    56                                               #Unpack and convert to numpy array\n",
      "    57       110   59629000.0 542081.8      0.6      x = np.array(data.x - 1) # x is the index of the observed state: We subtract 1 because python starts counting at 0\n",
      "    58       110    8363000.0  76027.3      0.1      d = np.array(data.d) # d is the observed decision\n",
      "    59       110    6804000.0  61854.5      0.1      dx1 = np.array(data.dx1) # dx1 is observed change in x \n",
      "    60                                           \n",
      "    61       110      77000.0    700.0      0.0      if no_guess == True: #Set ev to zero instead of using global variable\n",
      "    62                                                   ev = np.zeros((model.n))\n",
      "    63                                               \n",
      "    64                                               # Update values\n",
      "    65       110    1118000.0  10163.6      0.0      model=updatepar(model,pnames,theta)\n",
      "    66       110    1174000.0  10672.7      0.0      model.p = np.abs(model.p)    # helps BHHH which is run as unconstrained optimization\n",
      "    67       110   58884000.0 535309.1      0.6      model.create_grid() # Update grid\n",
      "    68       110      65000.0    590.9      0.0      ev0 = ev # Use previous value function as starting value\n",
      "    69                                           \n",
      "    70                                               # Solve the model\n",
      "    71       110 9750829000.0    9e+07     98.3      ev, pk, dev = solver.poly(model.bellman, V0=ev0 ,beta=model.beta, output=3)\n",
      "    72                                           \n",
      "    73                                               # Evaluate likelihood function\n",
      "    74       110    1993000.0  18118.2      0.0      lik_pr = pk[x] # Get probability of keeping given observed state    \n",
      "    75       110   10126000.0  92054.5      0.1      choice_prob = lik_pr * (1 - d) + (1-lik_pr) * d # get probability of making observed choice\n",
      "    76       110    7326000.0  66600.0      0.1      log_lik = np.log(choice_prob)  # Compute log-likelihood-contributions\n",
      "    77                                               \n",
      "    78                                               # add on log like for mileage process\n",
      "    79       110     131000.0   1190.9      0.0      if theta.size>2: # theta > 2 if there are parameters for p\n",
      "    80        31    1937000.0  62483.9      0.0          p = np.append(model.p,1-np.sum(model.p)) # Add residual probability to p\n",
      "    81        31     274000.0   8838.7      0.0          if any(p<=0):\n",
      "    82         5     165000.0  33000.0      0.0              log_lik -= 100000*p[dx1] # Penalize if p is negative\n",
      "    83                                                   else:\n",
      "    84        26    3042000.0 117000.0      0.0              log_lik += np.log(p[dx1]) # Add log-likelihood contribution\n",
      "    85                                                   \n",
      "    86                                               else:\n",
      "    87        79      39000.0    493.7      0.0          p = np.nan\n",
      "    88                                           \n",
      "    89                                           \n",
      "    90       110      72000.0    654.5      0.0      if out == 1:\n",
      "    91                                                   # Objective function (negative mean log likleihood)\n",
      "    92        55    3514000.0  63890.9      0.0          return np.mean(-log_lik)\n",
      "    93                                           \n",
      "    94        55     156000.0   2836.4      0.0      return model,lik_pr, pk, ev, dev, d,x,dx1"
     ]
    }
   ],
   "source": [
    "%lprun -f estimate.ll  -f estimate.estimate estimate.estimate(model, solver,data,theta0=theta0, twostep=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 0.140679 s\n",
      "File: /Users/jvander/Documents/Dynamic-Programming/Exercises/Discrete/Solve_NFXP.py\n",
      "Function: poly at line 31\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    31                                               def poly(self,bellman, V0=np.zeros(1), beta= 0.0, output=1):\n",
      "    32                                                   \"\"\"\" Solves the model using the poly-algorithm.\n",
      "    33                                                   set beta = 0.0 if you want to solve only with successive approximations.\n",
      "    34                                                   \"\"\"\n",
      "    35                                           \n",
      "    36         1       2000.0   2000.0      0.0          t0poly = time.time()  # set the starting time\n",
      "    37                                           \n",
      "    38                                                   # Loop over the maximum number of switches between contraction iterations and Newton-Kantorovich iterations\n",
      "    39         6       4000.0    666.7      0.0          for k in range(self.max_fxpiter):\n",
      "    40                                           \n",
      "    41                                                       # 1. CONTRACTION ITERATIONS (S-A)\n",
      "    42         5       3000.0    600.0      0.0              if self.printfxp>0:\n",
      "    43                                                           print(f'Begin contraction iterations (for the {k+1} time)')\n",
      "    44         5  128007000.0    3e+07     91.0              V0,iter_sa= self.sa(bellman,V0,beta)\n",
      "    45                                           \n",
      "    46                                                       # 2. NEWTON-KANTOROVICH ITERATIONS\n",
      "    47         5       1000.0    200.0      0.0              if self.printfxp>0:\n",
      "    48                                                           print(f'Begin Newton-Kantorovich iterations (for the {k+1} time)')\n",
      "    49         5   12654000.0    3e+06      9.0              V0,pk,dV, iter_nk = self.nk(bellman,V0)\n",
      "    50                                           \n",
      "    51                                           \n",
      "    52         5       2000.0    400.0      0.0              t1poly = time.time()\n",
      "    53         5       3000.0    600.0      0.0              if iter_nk.converged=='true':\n",
      "    54         5       1000.0    200.0      0.0                  if self.printfxp>0:\n",
      "    55                                                               print(f'Convergence achieved!')\n",
      "    56                                                               print(f'Elapsed time: {(t1poly-t0poly):.4f} (seconds)')\n",
      "    57                                                               break \n",
      "    58                                                       else:\n",
      "    59                                                           if k >= self.max_fxpiter:\n",
      "    60                                                               print(f'No convergence! Maximum number of iterations exceeded without convergence!')\n",
      "    61                                                               break\n",
      "    62         1          0.0      0.0      0.0          V = V0\n",
      "    63         1          0.0      0.0      0.0          if output==1:            \n",
      "    64         1       2000.0   2000.0      0.0              return V\n",
      "    65                                                   if output==2:            \n",
      "    66                                                       return V, pk\n",
      "    67                                                   if output==3:            \n",
      "    68                                                       return V, pk, dV\n",
      "    69                                                   if output==5:            \n",
      "    70                                                       return V, pk, dV, iter_sa, iter_nk\n",
      "    71                                                   else:\n",
      "    72                                                       print('solve_NFXP.poly: output must be 1,2,3 or 5')\n",
      "\n",
      "Total time: 0.012573 s\n",
      "File: /Users/jvander/Documents/Dynamic-Programming/Exercises/Discrete/Solve_NFXP.py\n",
      "Function: nk at line 117\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   117                                               def nk(self,bellman, V0):\n",
      "   118                                                   \"\"\"\"Solves the model using the Newton-Kantorovich steps\"\"\"\n",
      "   119                                                   #Empty class to store the iteration output\n",
      "   120         5      80000.0  16000.0      0.6          class iteration: pass\n",
      "   121         5       2000.0    400.0      0.0          t0 = time.time()\n",
      "   122         5      15000.0   3000.0      0.1          iteration.tol =  np.nan+np.zeros((self.pi_max))\n",
      "   123         5       9000.0   1800.0      0.1          iteration.rtol = np.nan+np.zeros((self.pi_max))\n",
      "   124         5          0.0      0.0      0.0          iteration.converged = 'false'\n",
      "   125                                                   # Get the state space size\n",
      "   126         5       3000.0    600.0      0.0          m = V0.size\n",
      "   127                                                   # Loop over the maximum number of Newton-Kantorovich steps\n",
      "   128        10       8000.0    800.0      0.1          for i in range(self.pi_max):\n",
      "   129                                           \n",
      "   130                                                       # NK-step\n",
      "   131        10    3199000.0 319900.0     25.4              V1, pk, dV = bellman(V0,output=3) # Get derivative of bellman operator\n",
      "   132        10     321000.0  32100.0      2.6              F = np.eye(m)-dV # Compute frechet derivative\n",
      "   133        10    8114000.0 811400.0     64.5              V = V0 - np.linalg.inv(F) @ (V0 - V1)  # Do N-K step\n",
      "   134                                                       \n",
      "   135                                                       # do additional SA iteration for stability and accurate measure of error bound\n",
      "   136        10     460000.0  46000.0      3.7              V0 = bellman(V,output=1)\n",
      "   137                                           \n",
      "   138                                                       # Tolerance\n",
      "   139        10     140000.0  14000.0      1.1              iteration.tol[i]=max(abs(V-V0))\n",
      "   140        10      15000.0   1500.0      0.1              iteration.rtol[i] = iteration.tol[i]/(iteration.tol[max(i-1,0)] + 1.0e-15)      \n",
      "   141                                           \n",
      "   142                                                       #Adjust \n",
      "   143        10     130000.0  13000.0      1.0              adj  = np.ceil(np.log10(abs(max(V0))))\n",
      "   144        10       7000.0    700.0      0.1              ltol = self.pi_tol*10**adj  # Adjust final tolerance\n",
      "   145                                           \n",
      "   146        10       6000.0    600.0      0.0              if iteration.tol[i] < ltol:\n",
      "   147                                                           #Convergence achieved\n",
      "   148         5      28000.0   5600.0      0.2                  iteration.message = \"N-K converged after {} iterations, tolerance: {:.4g}\".format(i+1,iteration.tol[i])\n",
      "   149         5       2000.0    400.0      0.0                  iteration.converged = 'true'\n",
      "   150         5       1000.0    200.0      0.0                  break\n",
      "   151                                                   # Store the iteration output\n",
      "   152         5          0.0      0.0      0.0          iteration.n = i+1\n",
      "   153         5       6000.0   1200.0      0.0          iteration.tol = iteration.tol[0:i+1]\n",
      "   154         5       3000.0    600.0      0.0          iteration.rtol = iteration.rtol[0:i+1]\n",
      "   155         5       3000.0    600.0      0.0          t1 = time.time()\n",
      "   156         5       2000.0    400.0      0.0          iteration.time = t1-t0 \n",
      "   157                                           \n",
      "   158         5       8000.0   1600.0      0.1          self.print_output(iteration)\n",
      "   159                                           \n",
      "   160         5      11000.0   2200.0      0.1          return V, pk, dV, iteration"
     ]
    }
   ],
   "source": [
    "ev0 = np.zeros((model.n)) # Initial guess\n",
    "%lprun -f solve_NFXP.nk -f solve_NFXP.poly solve_NFXP.poly(solver,model.bellman, ev0, beta = model.beta)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. In the code, we are using analytical hessian and gradient. Let us now try to use numerical equivalents. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Now try changing the optimizer options, and turn the use of the non-numerical Hessian off . What happens?\n",
    "\n",
    "b) Now also try it with the analytical gradient off, what happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BHHH:\n",
      "Time is 5.9588 seconds. The model converges: True\n",
      "Time is 5.4085 seconds. The model converges: True\n",
      "Time is 4.8234 seconds. The model converges: True\n",
      "Time is 4.8601 seconds. The model converges: True\n",
      "Time is 5.0020 seconds. The model converges: True\n",
      "Time is 5.1342 seconds. The model converges: True\n",
      "Time is 4.9835 seconds. The model converges: True\n",
      "Time is 5.0264 seconds. The model converges: True\n",
      "5.03 s ± 181 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "Hessian is off:\n",
      "Time is 11.3065 seconds. The model converges: True\n",
      "Time is 9.5301 seconds. The model converges: True\n",
      "Time is 10.9046 seconds. The model converges: True\n",
      "Time is 11.4470 seconds. The model converges: True\n",
      "Time is 9.4365 seconds. The model converges: True\n",
      "Time is 9.6362 seconds. The model converges: True\n",
      "Time is 9.6921 seconds. The model converges: True\n",
      "Time is 9.9190 seconds. The model converges: True\n",
      "10.1 s ± 721 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "Hessian and gradient are off:\n",
      "Time is 13.5654 seconds. The model converges: True\n",
      "Time is 12.8230 seconds. The model converges: True\n",
      "Time is 14.3189 seconds. The model converges: True\n",
      "Time is 12.4449 seconds. The model converges: True\n",
      "Time is 18.8371 seconds. The model converges: True\n",
      "Time is 34.6228 seconds. The model converges: True\n",
      "Time is 25.4099 seconds. The model converges: True\n",
      "Time is 34.1152 seconds. The model converges: True\n",
      "21.8 s ± 8.96 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "import alternative_specifications_ex7 as a_s_ex7\n",
    "import warnings\n",
    "# Turn off warnings: We turn of warnings as a result of overflow. This occurs as the optimizer will sometimes guess on non-feasible transition probabilities. \n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "model = zurcher()\n",
    "solver = solve_NFXP()\n",
    "\n",
    "#Ordinaty\n",
    "print('BHHH:')\n",
    "%timeit nfxp_results = a_s_ex7.estimate(model, solver,data,theta0=theta0, twostep=0,est_type=0)\n",
    "\n",
    "\n",
    "# Hessian off\n",
    "print('')\n",
    "print('Hessian is off:')\n",
    "%timeit nfxp_result = a_s_ex7.estimate(model, solver,data, twostep=0,est_type=1)\n",
    "\n",
    "\n",
    "# #Hessian and gradient ofF \n",
    "print('')\n",
    "print('Hessian and gradient are off:')\n",
    "%timeit nfxp_results = a_s_ex7.estimate(model, solver,data,theta0=theta0, twostep=0,est_type=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Try estimate the model for different values of $\\beta$. \n",
    "\n",
    "(a) Why can we not estimate $\\beta$?\n",
    "- The NFXP algorithm cannot seperately identify $\\beta$ as increasing $\\beta$ proportionally reduces both cost parameters, $\\textit{c}$ and $\\textit{RC}$, meaning different values of $\\beta$ can explain the same observed choices. Moreover, the Bellman equation is only identofied up to a scale, making it impossible to disentangle the effect of time discounting vs cost. \n",
    "\n",
    "(b) When estimating with different $\\beta$, do the changes in the estimates of c and/or RC make intuitively sense?\n",
    "- When $\\beta$ is low, the estimated cost parameters increase, as the model explains replacement behaviour through higher cost rather than discounting \n",
    "- When $\\beta$ is high, the estimated cost parameters decrease since agents are assumed to be more patient for future costs. \n",
    "\n",
    "(c) Can you think of some data/variation, which could allow us to identify $\\beta$?\n",
    "- Introducing credit constraints \n",
    "- Differing interest rates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta     RC     C       log_lik\n",
      "0.5000 7.3664 18.5137 [-8605.91245211] \n",
      "0.6666 7.4239 12.6984 [-8605.61914601] \n",
      "0.8333 7.6018 6.9196 [-8604.77884432] \n",
      "0.9999 9.7689 1.3427 [-8599.85577546] \n"
     ]
    }
   ],
   "source": [
    "# VARY BETA: \n",
    "Nbeta = 4\n",
    "beta = np.linspace(0.5,0.9999,Nbeta)\n",
    "log_lik = np.nan + np.zeros((Nbeta,1))\n",
    "theta_hats =  np.nan + np.zeros((Nbeta,2))\n",
    "\n",
    "data = model.read_busdata(bustypes=[1,2,3,4])\n",
    "samplesize = data.shape[0]\n",
    "\n",
    "print(f'beta     RC     C       log_lik')\n",
    "for i in range(Nbeta):\n",
    "    \n",
    "    # Set up the model\n",
    "    do_settings = {\n",
    "    'beta': beta[i]\n",
    "    }\n",
    "    model = zurcher(**do_settings)\n",
    "\n",
    "\n",
    "    # Set-up solver\n",
    "    solver = solve_NFXP()\n",
    "\n",
    "    # Estimate the model\n",
    "    theta0 = [0,0]\n",
    "    nfxp_model, optim_res, pnames, theta_hat, Avar, converged=estimate.estimate(model, solver,data,theta0=theta0, twostep=0)\n",
    "\n",
    "    \n",
    "    theta_hats[i,0] = theta_hat[0]\n",
    "    theta_hats[i,1] = theta_hat[1]\n",
    "    log_lik[i]=-optim_res.fun*samplesize\n",
    "    print(f'{beta[i]:.4f} {theta_hats[i,0]:.4f} {theta_hats[i,1]:.4f} {log_lik[i]} ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. We use the latest EV guess to start the solve-procedure even though we change $\\theta$ from one likelihood iteration to another. Why do you think we do that? \n",
    "- The Bellman operator is a contraction mapping, meaning that iterating from an already close guess, will converge much faster than restarting from an arbitrary initial condition. Resetting the solver to zero requires the solver to spend extra iterations on things, it has already been through \n",
    "- DP mpdels are highly recursive and value functions update slowly. Using the most recent value functions provides a smooth transitions in optimization rather than introducing artificial instability\n",
    "- Each likelihood iteration requires solving the Bellman equation many times. If one reset EV each time, we may throw away useful information aquired in the previous step, which only increase the computational burden. \n",
    "\n",
    "(a) What if we started over with EV=0 each iteration? Try that and see what happens with the parameters and the numerical performance.\n",
    "- The results are identical, but the time to get there is very different. \n",
    "- We see that the estimaton process is significantly slower when resetting each time. This is because the solver must recompute the entire value function from scrath at each iteration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same EV\n",
      "The slowest run took 6.43 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "12.1 s ± 6.03 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "EV=0\n",
      "The slowest run took 4.51 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "10.3 s ± 6.46 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "                 Same EV       EV=0\n",
      "RC               9.7689       9.7689\n",
      "c                1.3427       1.3427\n"
     ]
    }
   ],
   "source": [
    "import alternative_specifications_ex9 as a_s_ex9 \n",
    "\n",
    "# Ordinary\n",
    "print('Same EV')\n",
    "%timeit a_s_ex9.estimate(model, solver,data,0)\n",
    "nfxp_results_ord, theta_hat_ord = a_s_ex9.estimate(model, solver,data,0)\n",
    "\n",
    "\n",
    "# Change EV=0 in each iteration\n",
    "print('EV=0')\n",
    "%timeit a_s_ex9.estimate(model, solver,data,1)\n",
    "nfxp_results_diff, theta_hat_diff = a_s_ex9.estimate(model, solver,data,1)\n",
    "\n",
    "print('')\n",
    "print(f'                 Same EV       EV=0')\n",
    "print(f'{pnames[0]}               {theta_hat_ord[0]:.4f}       {theta_hat_diff[0]:.4f}')\n",
    "print(f'{pnames[1]}                {theta_hat_ord[1]:.4f}       {theta_hat_diff[1]:.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Try setting the maximum number of miles (odometer reading) to 720(multiplied previous maximum by 1.6). Now the absorbing state is much higher. \n",
    "\n",
    "(a) If we adjust the number of grid points as well, so that we have a comparable model (multiply the number of grids by 1.6), do we get a better fit? \n",
    "- The new grid better preserves the resolution of the state space by keeping the relative structure intact, but the parameter estimates for $\\textit{RC}$ and $\\textit{c}$ remain similar. Therefore, the change does not fundamentally improve the fit but maintains consistency.\n",
    "(b) Try to lower the number of grid points to 175 again. How do the parameters change? Are the changes intuitive? \n",
    "- Lowering the number of grid points reduces the resolution of the state space and we can see that estimates for $\\textit{RC}$ and $\\textit{c}$ shifht slightly. Therefore, lowering the grid points reduces precision and negatively impacts the likelihood, as expected.\n",
    "\n",
    "(c) Optional: What if you change the max to 225 and half the number of grids (hint: what goes wrong?)?\n",
    "- Reducing state space resolution too aggressively destroys structure needed for correct estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for adjusting Grid-points\n",
    "def adjust_grid_point(maks, n):\n",
    "    # Set up the model\n",
    "    do_settings = {\n",
    "    'max': maks,\n",
    "    'n': n\n",
    "    }\n",
    "    model = zurcher(**do_settings)\n",
    "\n",
    "    # Set-up solver\n",
    "    solver = solve_NFXP()\n",
    "        \n",
    "    # Read the data\n",
    "    data = model.read_busdata(bustypes=[1,2,3,4])\n",
    "    samplesize = data.shape[0]\n",
    "\n",
    "    # Estimate the model\n",
    "    theta0 = [0,0]\n",
    "    \n",
    "    nfxp_model, result, pnames, theta, Avar, converged=estimate.estimate(model, solver,data,theta0=theta0, twostep=0)\n",
    "\n",
    "    \n",
    "    print(f'Parameters     Estimates    s.e. ') \n",
    "    print(f'{pnames[0]}             {theta[0]:.4f}     {np.sqrt(Avar[0,0]):.4f} ')\n",
    "    print(f'{pnames[1]}              {theta[1]:.4f}     {np.sqrt(Avar[1,1]):.4f} \\n ')\n",
    "    print(f'Log-likelihood now {-result.fun*samplesize:.4f}\\n \\n') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline\n",
      "Parameters     Estimates    s.e. \n",
      "RC             9.7689     1.2264 \n",
      "c              1.3427     0.3153 \n",
      " \n",
      "Log-likelihood now -8599.8558\n",
      " \n",
      "\n",
      "Question (a)\n",
      "Parameters     Estimates    s.e. \n",
      "RC             9.7656     1.2381 \n",
      "c              1.3402     0.3204 \n",
      " \n",
      "Log-likelihood now -8599.8737\n",
      " \n",
      "\n",
      "Question (b)\n",
      "Parameters     Estimates    s.e. \n",
      "RC             9.7454     1.2336 \n",
      "c              2.1482     0.5138 \n",
      " \n",
      "Log-likelihood now -440060207.3012\n",
      " \n",
      "\n",
      "Question (c)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 87 is out of bounds for axis 0 with size 87",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# c) max =225, n = 175/2\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuestion (c)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m adjust_grid_point(\u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m450\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m),\u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m175\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m))\n",
      "Cell \u001b[0;32mIn[13], line 20\u001b[0m, in \u001b[0;36madjust_grid_point\u001b[0;34m(maks, n)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Estimate the model\u001b[39;00m\n\u001b[1;32m     18\u001b[0m theta0 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 20\u001b[0m nfxp_model, result, pnames, theta, Avar, converged\u001b[38;5;241m=\u001b[39mestimate\u001b[38;5;241m.\u001b[39mestimate(model, solver,data,theta0\u001b[38;5;241m=\u001b[39mtheta0, twostep\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mParameters     Estimates    s.e. \u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpnames[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m             \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtheta[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m     \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39msqrt(Avar[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Dynamic-Programming/Exercises/Discrete/estimate_NFXP.py:27\u001b[0m, in \u001b[0;36mestimate\u001b[0;34m(model, solver, data, theta0, twostep)\u001b[0m\n\u001b[1;32m     24\u001b[0m pnames \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRC\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Call BHHH optimizer\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m res \u001b[38;5;241m=\u001b[39m optimize\u001b[38;5;241m.\u001b[39mminimize(ll,theta0,args \u001b[38;5;241m=\u001b[39m (model, solver, data, pnames), method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrust-ncg\u001b[39m\u001b[38;5;124m'\u001b[39m,jac \u001b[38;5;241m=\u001b[39m grad, hess \u001b[38;5;241m=\u001b[39m hes, tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-8\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Update parameters\u001b[39;00m\n\u001b[1;32m     29\u001b[0m model \u001b[38;5;241m=\u001b[39m updatepar(model,pnames,res\u001b[38;5;241m.\u001b[39mx)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_minimize.py:732\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    729\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_dogleg(fun, x0, args, jac, hess,\n\u001b[1;32m    730\u001b[0m                            callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrust-ncg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 732\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_trust_ncg(fun, x0, args, jac, hess, hessp,\n\u001b[1;32m    733\u001b[0m                               callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrust-krylov\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    735\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_trust_krylov(fun, x0, args, jac, hess, hessp,\n\u001b[1;32m    736\u001b[0m                                  callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_trustregion_ncg.py:37\u001b[0m, in \u001b[0;36m_minimize_trust_ncg\u001b[0;34m(fun, x0, args, jac, hess, hessp, **trust_region_options)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hess \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m hessp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEither the Hessian or the Hessian-vector product \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     36\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis required for Newton-CG trust-region minimization\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _minimize_trust_region(fun, x0, args\u001b[38;5;241m=\u001b[39margs, jac\u001b[38;5;241m=\u001b[39mjac, hess\u001b[38;5;241m=\u001b[39mhess,\n\u001b[1;32m     38\u001b[0m                               hessp\u001b[38;5;241m=\u001b[39mhessp, subproblem\u001b[38;5;241m=\u001b[39mCGSteihaugSubproblem,\n\u001b[1;32m     39\u001b[0m                               \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrust_region_options)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_trustregion.py:175\u001b[0m, in \u001b[0;36m_minimize_trust_region\u001b[0;34m(fun, x0, args, jac, hess, hessp, subproblem, initial_trust_radius, max_trust_radius, eta, gtol, maxiter, disp, return_all, callback, inexact, **unknown_options)\u001b[0m\n\u001b[1;32m    171\u001b[0m x0 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x0)\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# A ScalarFunction representing the problem. This caches calls to fun, jac,\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# hess.\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m sf \u001b[38;5;241m=\u001b[39m _prepare_scalar_function(fun, x0, jac\u001b[38;5;241m=\u001b[39mjac, hess\u001b[38;5;241m=\u001b[39mhess, args\u001b[38;5;241m=\u001b[39margs)\n\u001b[1;32m    176\u001b[0m fun \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mfun\n\u001b[1;32m    177\u001b[0m jac \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mgrad\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_optimize.py:288\u001b[0m, in \u001b[0;36m_prepare_scalar_function\u001b[0;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[1;32m    284\u001b[0m     bounds \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf, np\u001b[38;5;241m.\u001b[39minf)\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# calculation reduces overall function evaluations.\u001b[39;00m\n\u001b[0;32m--> 288\u001b[0m sf \u001b[38;5;241m=\u001b[39m ScalarFunction(fun, x0, args, grad, hess,\n\u001b[1;32m    289\u001b[0m                     finite_diff_rel_step, bounds, epsilon\u001b[38;5;241m=\u001b[39mepsilon)\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sf\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:166\u001b[0m, in \u001b[0;36mScalarFunction.__init__\u001b[0;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m fun_wrapped(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun_impl \u001b[38;5;241m=\u001b[39m update_fun\n\u001b[0;32m--> 166\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Gradient evaluation\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(grad):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:262\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun_impl()\n\u001b[1;32m    263\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:163\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m fun_wrapped(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:145\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m fx \u001b[38;5;241m=\u001b[39m fun(np\u001b[38;5;241m.\u001b[39mcopy(x), \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m~/Documents/Dynamic-Programming/Exercises/Discrete/estimate_NFXP.py:74\u001b[0m, in \u001b[0;36mll\u001b[0;34m(theta, model, solver, data, pnames, out, no_guess)\u001b[0m\n\u001b[1;32m     71\u001b[0m ev, pk, dev \u001b[38;5;241m=\u001b[39m solver\u001b[38;5;241m.\u001b[39mpoly(model\u001b[38;5;241m.\u001b[39mbellman, V0\u001b[38;5;241m=\u001b[39mev0 ,beta\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mbeta, output\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Evaluate likelihood function\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m lik_pr \u001b[38;5;241m=\u001b[39m pk[x] \u001b[38;5;66;03m# Get probability of keeping given observed state    \u001b[39;00m\n\u001b[1;32m     75\u001b[0m choice_prob \u001b[38;5;241m=\u001b[39m lik_pr \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m d) \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mlik_pr) \u001b[38;5;241m*\u001b[39m d \u001b[38;5;66;03m# get probability of making observed choice\u001b[39;00m\n\u001b[1;32m     76\u001b[0m log_lik \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(choice_prob)  \u001b[38;5;66;03m# Compute log-likelihood-contributions\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 87 is out of bounds for axis 0 with size 87"
     ]
    }
   ],
   "source": [
    "# Baseline max = 450, n = 175\n",
    "print(f'Baseline')\n",
    "adjust_grid_point(450,175)\n",
    "\n",
    "# a)  max = 720, n = 280\n",
    "print(f'Question (a)')\n",
    "adjust_grid_point(int(450*1.6),int(175*1.6))\n",
    "\n",
    "# b) max = 720., n = 175\n",
    "print(f'Question (b)')\n",
    "adjust_grid_point(int(450*1.6),175)\n",
    "\n",
    "# c) max =225, n = 175/2\n",
    "print(f'Question (c)')\n",
    "adjust_grid_point(int(450/2),int(175/2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "d23f3ceec305a45481076084313530cecc6283a24046b34365f00383ab0a81b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
