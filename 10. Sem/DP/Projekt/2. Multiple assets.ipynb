{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89753fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import itertools, time\n",
    "from numpy.polynomial.chebyshev import chebvander\n",
    "from numpy.polynomial.laguerre import lagvander\n",
    "from scipy.stats import norm\n",
    "from numpy.polynomial.hermite import hermvander\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\", palette=\"muted\", font_scale=1.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8b4ae5",
   "metadata": {},
   "source": [
    "# N-dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a865487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_gbm_nd(S0, sigma, R, r, T, N_steps, N_paths, seed=None):\n",
    "    \"\"\"\n",
    "    Simulate n-dimensional correlated GBM under the risk-neutral measure\n",
    "    using antithetic variates.\n",
    "\n",
    "    Args:\n",
    "        S0: initial prices, array-like of shape (n,)\n",
    "        sigma: volatilities, array-like of shape (n,)\n",
    "        R: correlation matrix, shape (n, n)\n",
    "        r: risk-free rate\n",
    "        T: time to maturity\n",
    "        N_steps: number of time steps\n",
    "        N_paths: total number of simulation paths (must be even)\n",
    "        seed: optional random seed\n",
    "\n",
    "    Returns:\n",
    "        paths: ndarray of shape (N_paths, N_steps+1, n)\n",
    "    \"\"\"\n",
    "    S0 = np.array(S0, dtype=float)\n",
    "    sigma = np.array(sigma, dtype=float)\n",
    "    n = len(S0)\n",
    "\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    assert N_paths % 2 == 0, \"N_paths must be even for antithetic sampling\"\n",
    "\n",
    "    dt = T / N_steps\n",
    "    L = np.linalg.cholesky(R)\n",
    "\n",
    "    paths = np.zeros((N_paths, N_steps+1, n))\n",
    "    paths[:, 0, :] = S0\n",
    "\n",
    "    half = N_paths // 2\n",
    "    drift = (r - 0.5 * sigma**2) * dt\n",
    "\n",
    "    for t in range(1, N_steps+1):\n",
    "        Z_small = np.random.normal(size=(half, n))\n",
    "        Z = np.vstack([Z_small, -Z_small])\n",
    "        dW = Z @ L.T * np.sqrt(dt)\n",
    "        diffusion = sigma * dW\n",
    "        paths[:, t, :] = paths[:, t-1, :] * np.exp(drift + diffusion)\n",
    "\n",
    "    return paths\n",
    "\n",
    "\n",
    "def lsm_price_nd(paths, K, r, w, basis_functions, dt, is_call=False):\n",
    "    \"\"\"\n",
    "    Price an American-style option on a weighted sum via the Longstaff - Schwartz method,\n",
    "    but perform all regressions on the normalized state S/K.\n",
    "    \"\"\"\n",
    "    N_paths, N_steps_plus1, _ = paths.shape\n",
    "    discount = np.exp(-r * dt)\n",
    "    w = np.array(w)\n",
    "    sign = 1 if is_call else -1\n",
    "\n",
    "    # Value‐matrix: rows=paths, cols=time‐steps\n",
    "    V = np.zeros((N_paths, N_steps_plus1))\n",
    "    V[:, -1] = np.maximum(sign * (paths[:, -1, :] @ w - K), 0)\n",
    "\n",
    "    # Backward induction over all intermediate exercise dates\n",
    "    for t in range(N_steps_plus1 - 2, 0, -1):\n",
    "        S_t    = paths[:, t, :]\n",
    "        payoff = np.maximum(sign * (S_t @ w - K), 0)\n",
    "        itm    = payoff > 0\n",
    "        cont   = discount * V[:, t + 1]\n",
    "\n",
    "        # Non‐ITM simply continuation\n",
    "        V[~itm, t] = cont[~itm]\n",
    "\n",
    "        if np.any(itm):\n",
    "            # 1) extract the raw in‐the‐money sub‐paths\n",
    "            S_itm = S_t[itm]                     # shape = (N_itm, n)\n",
    "\n",
    "            # 2) **normalize** by strike\n",
    "            S_itm_scaled = S_itm / K             # dimensionless input\n",
    "\n",
    "            # 3) build the regression matrix on S/K\n",
    "            B = np.vstack([f(S_itm_scaled) for f in basis_functions]).T\n",
    "\n",
    "            X       = B\n",
    "            Y       = cont[itm]\n",
    "            model   = LinearRegression().fit(X, Y)\n",
    "            cont_fit = model.predict(X)\n",
    "\n",
    "            # Decide exercise versus continuation\n",
    "            exercise     = payoff[itm] > cont_fit\n",
    "            V[itm, t]    = np.where(exercise, payoff[itm], cont[itm])\n",
    "\n",
    "    # At t=0, compare immediate exercise to continuation\n",
    "    payoff0 = np.maximum(sign * (paths[:, 0, :] @ w - K), 0)\n",
    "    cont0   = discount * V[:, 1]\n",
    "    V0      = np.where(payoff0 > cont0, payoff0, cont0)\n",
    "\n",
    "    price  = V0.mean()\n",
    "    stderr = V0.std(ddof=1) / np.sqrt(N_paths)\n",
    "    return float(price), float(stderr)\n",
    "\n",
    "\n",
    "def scale_to_unit(x):\n",
    "    \"\"\"\n",
    "    Scale array x to [-1, 1] using its own min and max.\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    a, b = x.min(), x.max()\n",
    "    if b == a:\n",
    "        return np.zeros_like(x)\n",
    "    return 2 * (x - a) / (b - a) - 1\n",
    "\n",
    "def chebyshev_basis_nd(n, degree):\n",
    "    indices = list(itertools.product(range(degree+1), repeat=n))\n",
    "    def make_fn(alpha):\n",
    "        def fn(S):\n",
    "            feat = None\n",
    "            for j, power in enumerate(alpha):\n",
    "                xj = scale_to_unit(S[:, j])\n",
    "                Tj = chebvander(xj, degree)[:, power]\n",
    "                feat = Tj if feat is None else feat * Tj\n",
    "            return feat\n",
    "        return fn\n",
    "    return [make_fn(alpha) for alpha in indices]\n",
    "\n",
    "def laguerre_basis_nd(n, degree):\n",
    "    indices = list(itertools.product(range(degree+1), repeat=n))\n",
    "    def make_fn(alpha):\n",
    "        def fn(S):\n",
    "            mats = [lagvander(S[:, j], degree)[:, alpha[j]] for j in range(n)]\n",
    "            feat = mats[0]\n",
    "            for mat in mats[1:]:\n",
    "                feat = feat * mat\n",
    "            return feat\n",
    "        return fn\n",
    "    return [make_fn(alpha) for alpha in indices]\n",
    "\n",
    "def hermite_basis_nd(n, degree):\n",
    "    indices = list(itertools.product(range(degree+1), repeat=n))\n",
    "    def make_fn(alpha):\n",
    "        def fn(S):\n",
    "            mats = [hermvander(S[:, j], degree)[:, alpha[j]] for j in range(n)]\n",
    "            feat = mats[0]\n",
    "            for mat in mats[1:]:\n",
    "                feat = feat * mat\n",
    "            return feat\n",
    "        return fn\n",
    "    return [make_fn(alpha) for alpha in indices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9417a0ea",
   "metadata": {},
   "source": [
    "We were initially planning on having both sigma at 0.2 and 0.4, but since we saw no point in presenting it too, we chose to simply run with 0.2. This is the reason most of this part of the code is written inside vol_list loops. Furthermore, in order to change the number of assets to 5, simply switch the n to 5. It shall be noted, that we had to ask a friend for computer power(GPU), as our own CPU's did not have sufficient power. Therefore, all the results, will not be shown here, but the code matches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "436c2535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=2, σ=0.20, Basis=Chebyshev : Price=1.6609 ± 0.0064   (computed in 3.130 s)\n",
      "n=2, σ=0.20, Basis=Laguerre  : Price=1.6609 ± 0.0064   (computed in 2.731 s)\n",
      "n=2, σ=0.20, Basis=Hermite   : Price=1.6609 ± 0.0064   (computed in 4.648 s)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    n = 2\n",
    "    S0 = [40.0]*n\n",
    "    r = 0.06\n",
    "    T = 1.0\n",
    "    N_steps = 50\n",
    "    N_paths = 100000\n",
    "    K = 40.0\n",
    "    w = [1/n]*n\n",
    "    seed = 2025\n",
    "\n",
    "    rho = 0.2\n",
    "    R = np.full((n, n), rho)\n",
    "    np.fill_diagonal(R, 1.0)\n",
    "\n",
    "    vol_list = [0.2]\n",
    "    basis_gens = {\n",
    "        'Chebyshev': chebyshev_basis_nd,\n",
    "        'Laguerre':  laguerre_basis_nd,\n",
    "        'Hermite':   hermite_basis_nd\n",
    "    }\n",
    "    degree = 3\n",
    "\n",
    "    dt = T / N_steps\n",
    "    for vol in vol_list:\n",
    "        sigma = [vol]*n\n",
    "        paths = simulate_gbm_nd(S0, sigma, R, r, T, N_steps, N_paths, seed)\n",
    "\n",
    "        for name, gen in basis_gens.items():\n",
    "            basis = gen(n, degree)\n",
    "\n",
    "            # Start timer\n",
    "            t0 = time.perf_counter()\n",
    "            price, stderr = lsm_price_nd(paths, K, r, w, basis, dt=dt, is_call=False)\n",
    "            # Stop timer\n",
    "            elapsed = time.perf_counter() - t0\n",
    "\n",
    "            print(\n",
    "                f\"n={n}, σ={vol:.2f}, Basis={name:9s} : \"\n",
    "                f\"Price={price:.4f} ± {stderr:.4f}   \"\n",
    "                f\"(computed in {elapsed:.3f} s)\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215b2d6b",
   "metadata": {},
   "source": [
    "# European Check\n",
    "The European basket of option should yield a lower price because the time option embedded into the American should be above 0, which pushes the American price above the European. Therefore, if the price is not eqvalent or higher than the European price, we have priced it wrong. This is theory is not gone through in the assignment itself, but it is in place to compute the European check. As this is a closed formula, this could in theory be solved by pen and paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d296eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for sigma = 0.20:\n",
      " European basket-put price (2 assets): 1.4103\n",
      " European basket-put price (5 assets): 0.9205\n",
      "\n",
      "Results for sigma = 0.40:\n",
      " European basket-put price (2 assets): 3.7051\n",
      " European basket-put price (5 assets): 2.6594\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def basket_put_price(S, K, r, sigma, rho, T, weights=None):\n",
    "    \"\"\"\n",
    "    Calculates the price of an European basket-put under the Black-76 scheme\n",
    "\n",
    "    Parameters:\n",
    "        S       : Array of stock prices at t0 given as S_i\n",
    "        K       : Strikeprice, same for all assets\n",
    "        r       : Risk-free rate (annualized) \n",
    "        sigma   : Volatilities σ_i (scalar for uniform or array for individual)\n",
    "        rho     : correlation matrix ρ (scalar for uniform or array for individual)\n",
    "        T       : Time to maturity (in years)\n",
    "        weights : weights for each asset, they are set to equal\n",
    "\n",
    "    Returns:\n",
    "        price of a put (float)\n",
    "    \"\"\"\n",
    "    # Konverter inputs til numpy arrays\n",
    "    S = np.array(S, dtype=float)\n",
    "    n = len(S)\n",
    "\n",
    "    # Weights: default to equal and normalize\n",
    "    if weights is None:\n",
    "        weights = np.full(n, 1.0 / n)\n",
    "    else:\n",
    "        weights = np.array(weights, dtype=float)\n",
    "        weights = weights / np.sum(weights)\n",
    "\n",
    "    # Volatiliteter: ensartet eller per aktiv\n",
    "    if np.isscalar(sigma):\n",
    "        sigma = np.full(n, sigma)\n",
    "    else:\n",
    "        sigma = np.array(sigma, dtype=float)\n",
    "\n",
    "    # Korrelationsmatrix\n",
    "    if np.isscalar(rho):\n",
    "        corr = np.full((n, n), rho)\n",
    "        np.fill_diagonal(corr, 1.0)\n",
    "    else:\n",
    "        corr = np.array(rho, dtype=float)\n",
    "        if not np.allclose(corr, corr.T):\n",
    "            raise ValueError(\"Correlation matrix must be symmetric\")\n",
    "\n",
    "    # Covariance Σ = D · corr · D\n",
    "    D = np.diag(sigma)\n",
    "    Sigma = D @ corr @ D\n",
    "\n",
    "    # Beregn basket-forward og forward-volatilitet\n",
    "    B0 = np.dot(weights, S)\n",
    "    FB = B0 * np.exp(r * T)\n",
    "    sigmaB2 = weights @ Sigma @ weights\n",
    "    sigmaB = np.sqrt(sigmaB2)\n",
    "\n",
    "    # Håndter degenererede tilfælde\n",
    "    if sigmaB <= 0 or T <= 0:\n",
    "        return max(K - B0, 0) * np.exp(-r * T)\n",
    "\n",
    "    # Black-76 d1 og d2\n",
    "    d1 = (np.log(FB / K) + 0.5 * sigmaB2 * T) / (sigmaB * np.sqrt(T))\n",
    "    d2 = d1 - sigmaB * np.sqrt(T)\n",
    "\n",
    "    # Price put under Black-76\n",
    "    put_price = np.exp(-r * T) * (K * norm.cdf(-d2) - FB * norm.cdf(-d1))\n",
    "    return put_price\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Eksempelparametre\n",
    "    K = 40\n",
    "    r = 0.06\n",
    "    rho = 0.2\n",
    "    T = 1.0\n",
    "    S0 = 40\n",
    "    sigma_values = [0.2, 0.4]\n",
    "\n",
    "    for sigma in sigma_values:\n",
    "        print(f\"Results for sigma = {sigma:.2f}:\")\n",
    "\n",
    "        # 2 aktiver\n",
    "        price_2 = basket_put_price(\n",
    "            S=[S0, S0],\n",
    "            K=K,\n",
    "            r=r,\n",
    "            sigma=sigma,\n",
    "            rho=rho,\n",
    "            T=T\n",
    "        )\n",
    "        print(f\" European basket-put price (2 assets): {price_2:.4f}\")\n",
    "\n",
    "        # 5 aktiver\n",
    "        price_5 = basket_put_price(\n",
    "            S=[S0] * 5,\n",
    "            K=K,\n",
    "            r=r,\n",
    "            sigma=sigma,\n",
    "            rho=rho,\n",
    "            T=T\n",
    "        )\n",
    "        print(f\" European basket-put price (5 assets): {price_5:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0241330",
   "metadata": {},
   "source": [
    "Since the price for all the different basis functions are above the European counterpart, and is not very far from the European price. We will argue, that this price is somewhat fair for the basket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc75a1a",
   "metadata": {},
   "source": [
    "# Convergence Test\n",
    "\n",
    "We now turn towards convergence test, here we make three difffernt test. Firstly, the $[\\texttt{test\\_time\\_convergence}]$$. This keeps the sample size fixed, but refines the exercise grid $\\Delta_t = \\frac{T}{N_{\\mathrm{steps}}}$ with $N_{\\mathrm{steps}} \\in [10,25,50,100,200]$ and computes the LSM price at each refinement. We do this as the American option price should converge as the finer grid we use. I.e. we verify that our backward-induction method is consistent and our time‐discretization error vanishes in $N$. \n",
    "\n",
    "Secondly, $[\\texttt{test\\_mc\\_convergence}]$. This holds the time grid fixed at $N_{\\mathrm{steps}}=50$, but increases the number of simulated paths. Since LSM is a Monte Carlo method, the statistical error should scale like $(N_{\\mathrm{paths}}^{-1/2})$. Therefore, the more paths, the more stable our price should become. \n",
    "\n",
    "Lastly, we have $[\\texttt{test\\_basis\\_convergence}]$. This keeps both the grid and the sample size consistent, but will vary the polynomial basis degree, $d = 1,\\dots,\\mathrm{max\\_deg}$. Since the regression basis approximates the true continuation-value function, we should see the price stabilize once the basis is sufficiently rich, or might locate eventual overfitting. In order to have the convergence plots for the basis functions, we had to cap it at d=4. \n",
    "\n",
    "Can be taken one at a time, or just run the whole script at once. Does take a while.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e69ebb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "basis_gens = {\n",
    "        'Chebyshev': chebyshev_basis_nd,\n",
    "        'Laguerre':  laguerre_basis_nd,\n",
    "        'Hermite':   hermite_basis_nd\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6c3070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n = 2\n",
    "S0 = [40.0] * n\n",
    "sigma = [0.2] * n\n",
    "rho = 0.2\n",
    "R = np.full((n, n), rho)\n",
    "np.fill_diagonal(R, 1.0)\n",
    "r, T, K = 0.06, 1.0, 40.0\n",
    "w = [1.0/n] * n\n",
    "seed = 2025\n",
    "\n",
    "# Fine‐grid / max‐sample settings\n",
    "N_steps_max = 200\n",
    "N_paths_max = 200_000\n",
    "dt_max = T / N_steps_max\n",
    "\n",
    "# Simulate once at the finest grid & sample\n",
    "paths_max = simulate_gbm_nd(S0, sigma, R, r, T, N_steps_max, N_paths_max, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185d1298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Convergence tests using Hermite basis ===\n"
     ]
    }
   ],
   "source": [
    "# Loop over each basis family\n",
    "for basis_name, gen in basis_gens.items():\n",
    "    print(f\"\\n=== Convergence tests using {basis_name} basis ===\")\n",
    "\n",
    "   \n",
    "    basis3 = gen(n, 3)\n",
    "\n",
    "    # 1) Time‐step convergence\n",
    "    time_res = []\n",
    "    for N_steps in [10, 25, 50, 100, 200]:\n",
    "        step = N_steps_max // N_steps\n",
    "        coarse = paths_max[:, ::step, :]\n",
    "        dt = T / N_steps\n",
    "        price, _ = lsm_price_nd(coarse, K, r, w, basis3, dt)\n",
    "        time_res.append((N_steps, dt, price))\n",
    "\n",
    "    # Plot\n",
    "    _, dts, prices = zip(*time_res)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    ax.plot(dts, prices,\n",
    "            marker='o', linestyle='-',\n",
    "            linewidth=1.5, markersize=6,\n",
    "            label='Price')\n",
    "\n",
    "    # Use a log‐scale on x, but with plain numeric labels\n",
    "    ax.set_xscale('log')\n",
    "    ax.xaxis.set_major_formatter(ScalarFormatter())\n",
    "    ax.ticklabel_format(axis='x', style='plain')\n",
    "\n",
    "    # Grid, labels, title\n",
    "    ax.grid(True, which='both', linestyle='--', alpha=0.5)\n",
    "    ax.set_xlabel(r'$\\Delta t$ (years)', fontsize=12)\n",
    "    ax.set_ylabel('American put price', fontsize=12)\n",
    "    # ax.set_title(f'Time step Convergence ({basis_name})', fontsize=14)\n",
    "    ax.legend()\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 2) Monte Carlo convergence\n",
    "    mc_res = []\n",
    "    # reuse the same 50-step slicing:\n",
    "    paths50 = paths_max[:, ::(N_steps_max//50), :]\n",
    "    dt50 = T / 50\n",
    "    for N in [10_000, 25_000, 50_000, 100_000, 200_000]:\n",
    "        subset = paths50[:N]\n",
    "        price, stderr = lsm_price_nd(subset, K, r, w, basis3, dt50)\n",
    "        mc_res.append((N, price, stderr))\n",
    "\n",
    "    # Plot\n",
    "    Ns, Ps, Es = zip(*mc_res)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    ax.errorbar(Ns, Ps, yerr=Es,\n",
    "            fmt='o-', capsize=4,\n",
    "            linewidth=1.5, markersize=6,\n",
    "            label='Price ± SE')\n",
    "\n",
    "    # Log‐scale x with plain numeric labels\n",
    "    ax.set_xscale('log')\n",
    "    ax.xaxis.set_major_formatter(ScalarFormatter())\n",
    "    ax.ticklabel_format(axis='x', style='plain')\n",
    "\n",
    "    # Grid, labels, title\n",
    "    ax.grid(True, which='both', linestyle='--', alpha=0.5)\n",
    "    ax.set_xlabel('Number of paths', fontsize=12)\n",
    "    ax.set_ylabel('American put price', fontsize=12)\n",
    "    # ax.set_title(f'Monte Carlo Convergence ({basis_name})', fontsize=14)\n",
    "    ax.legend()\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    3) Basis-degree convergence\n",
    "    basis_res = []\n",
    "    for degree in [1, 2, 3, 4]:\n",
    "        basis_d = gen(n, degree)\n",
    "        price, stderr = lsm_price_nd(paths50, K, r, w, basis_d, dt50)\n",
    "        basis_res.append((degree, price, stderr))\n",
    "\n",
    "    # Plot\n",
    "    Ds, Ps2, Es2 = zip(*basis_res)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    ax.errorbar(Ds, Ps2, yerr=Es2,\n",
    "            fmt='o-', capsize=4,\n",
    "            linewidth=1.5, markersize=6,\n",
    "            label='Price ± SE')\n",
    "\n",
    "    ax.grid(True, linestyle='--', alpha=0.5)\n",
    "    ax.set_xlabel('Polynomial degree', fontsize=12)\n",
    "    ax.set_ylabel('American put price', fontsize=12)\n",
    "    # ax.set_title(f'Basis Convergence ({basis_name})', fontsize=14)\n",
    "    ax.set_xticks(Ds)   # ensure integer tick marks\n",
    "    ax.legend()\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b637198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(10, 0.1, 1.1597454357453172), (25, 0.04, 1.1809563861474892), (50, 0.02, 1.1895097811283462), (100, 0.01, 1.19248222497462), (200, 0.005, 1.1965066774902844)]\n",
      "[(10000, 1.5153512440403214, 0.0178555105875514), (25000, 1.3263618099064325, 0.010224532006040512), (50000, 1.2527700632804912, 0.0067963973807822955), (100000, 1.214195241219224, 0.004679745813444817), (200000, 1.1895097811283462, 0.0032655591148353044)]\n",
      "[(1, 1.1456316896674226, 0.0033320906034070103), (2, 1.1699743107141258, 0.0032604371941081464), (3, 1.1895097811283462, 0.0032655591148353044), (4, 1.2334669576193726, 0.003360618795882683)]\n"
     ]
    }
   ],
   "source": [
    "# print(time_res)\n",
    "# print(mc_res)\n",
    "# print(basis_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8e4db9",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "\n",
    "In order to tackle some of our efficiency problems with the rising number of approximations, we will try to incorporate a Neural Network, to see if this will better price the options. Both more accurately and faster. \n",
    "\n",
    "We run a setup equivalent to the extended LSM model, but we change the way, we approximate the continuation value. Instead of using regression, we replace it with a network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50a14a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "def mlp_lsm(paths_nd, w, r, K, T):\n",
    "    \"\"\"\n",
    "    Price an American‐style basket put via LSM with an n-dimensional MLP,\n",
    "    and compute its Monte Carlo standard error.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    paths_nd : np.ndarray, shape (N_paths, N_steps+1, n_assets)\n",
    "        Simulated correlated GBM paths.\n",
    "    w : array-like, shape (n_assets,)\n",
    "        Basket weights (must sum to 1).\n",
    "    r : float\n",
    "        Continuously compounded risk-free rate.\n",
    "    K : float\n",
    "        Strike price.\n",
    "    T : float\n",
    "        Time to maturity (years).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    price : float\n",
    "        Estimated option price.\n",
    "    stderr : float\n",
    "        Monte Carlo standard error of the estimate.\n",
    "    \"\"\"\n",
    "    N_paths, N_steps1, _ = paths_nd.shape\n",
    "    N_steps = N_steps1 - 1\n",
    "    dt = T / N_steps\n",
    "    df = np.exp(-r * dt)\n",
    "\n",
    "    # basket price at each time: shape (N_paths, N_steps+1)\n",
    "    basket = np.tensordot(paths_nd, w, axes=(2, 0))\n",
    "\n",
    "    # initialize cash flows at maturity (time T)\n",
    "    cash_flow = np.maximum(K - basket[:, -1], 0)\n",
    "\n",
    "    # backward induction\n",
    "    for t in range(N_steps - 1, 0, -1):\n",
    "        # discount back one step (from t+dt to t)\n",
    "        cash_flow *= df\n",
    "\n",
    "        # immediate payoff at t\n",
    "        immediate = np.maximum(K - basket[:, t], 0)\n",
    "        itm = immediate > 0\n",
    "\n",
    "        if np.any(itm):\n",
    "            # train MLP on in‐the‐money paths\n",
    "            X = paths_nd[itm, t, :]      # (n_itm, n_assets)\n",
    "            Y = cash_flow[itm]           # (n_itm,)\n",
    "            mlp = MLPRegressor(\n",
    "                hidden_layer_sizes=(40, 40),\n",
    "                activation='relu',\n",
    "                solver='adam',\n",
    "                batch_size=512,\n",
    "                learning_rate='adaptive',\n",
    "                learning_rate_init=0.001,\n",
    "                max_iter=200,\n",
    "                random_state=42,\n",
    "            )\n",
    "            mlp.fit(X, Y)\n",
    "\n",
    "            # predict continuation for all paths\n",
    "            cont = mlp.predict(paths_nd[:, t, :])\n",
    "\n",
    "            # exercise when immediate ≥ continuation\n",
    "            exercise = itm & (immediate >= cont)\n",
    "            cash_flow[exercise] = immediate[exercise]\n",
    "\n",
    "    # final discount from t=dt back to t=0\n",
    "    discounted = cash_flow * df\n",
    "    price = np.mean(discounted)\n",
    "    stderr = np.std(discounted, ddof=1) / np.sqrt(N_paths)\n",
    "    return price, stderr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "322913c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=5, σ=0.20, MLP‑LSM (n‑dim) basket price = 0.9146 ± 0.0029   (computed in 1457.105 s)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # === Parameters ===\n",
    "    n       = 5\n",
    "    S0      = [40.0] * n\n",
    "    r       = 0.06\n",
    "    T       = 1.0\n",
    "    N_steps = 50\n",
    "    N_paths = 100000\n",
    "    K       = 40.0\n",
    "    w       = [1.0 / n] * n\n",
    "    seed    = 2025\n",
    "    rho     = 0.2\n",
    "\n",
    "    # Build correlation matrix\n",
    "    R = np.full((n, n), rho)\n",
    "    np.fill_diagonal(R, 1.0)\n",
    "\n",
    "    # Simulate GBM paths\n",
    "    paths_nd = simulate_gbm_nd(\n",
    "        S0=S0,\n",
    "        sigma=[0.2] * n,\n",
    "        R=R,\n",
    "        r=r,\n",
    "        T=T,\n",
    "        N_steps=N_steps,\n",
    "        N_paths=N_paths,\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "    # Time the MLP–LSM basket price computation\n",
    "    t_start = time.perf_counter()\n",
    "    mlp_price, mlp_error = mlp_lsm(paths_nd, w, r, K, T)\n",
    "    t_elapsed = time.perf_counter() - t_start\n",
    "\n",
    "    # Report price and timing\n",
    "    print(\n",
    "        f\"n={n}, σ=0.20, \"\n",
    "        f\"MLP‑LSM (n‑dim) basket price = {mlp_price:.4f} ± {mlp_error:.4f}   \"\n",
    "        f\"(computed in {t_elapsed:.3f} s)\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
