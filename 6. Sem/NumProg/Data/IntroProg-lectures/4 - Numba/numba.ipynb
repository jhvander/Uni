{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# numba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- 1. [Introduction](#toc1_)    \n",
    "- 2. [Further speed-up](#toc2_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=true\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=2\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be introduced to how  to use the **numba** package to speed-up your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({\"axes.grid\":True,\"grid.color\":\"black\",\"grid.alpha\":\"0.25\",\"grid.linestyle\":\"--\"})\n",
    "plt.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "CPUs = psutil.cpu_count()\n",
    "CPUs_list = set(np.sort([1,2,4,*np.arange(8,CPUs+1,4)])) \n",
    "print(f'this computer has {CPUs} CPUs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. <a id='toc1_'></a>[Introduction](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing **vectorized code can be cumbersome**, and in some cases it is impossible. Instead we can use the **numba** module. \n",
    "\n",
    "Adding the decorator `nb.njit` on top of a function tells numba to compile this function **to machine code just-in-time**. This takes some time when the function is called the first time, but subsequent calls are then a lot faster. *The input types can, however, not change between calls because numba infer them on the first call.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myfun_numpy_vec(x1,x2):\n",
    "    y = np.empty((1,x1.size))\n",
    "    I = x1 < 0.5\n",
    "    y[I] = np.sum(np.exp(x2*x1[I]),axis=0)\n",
    "    y[~I] = np.sum(np.log(x2*x1[~I]),axis=0)\n",
    "    return y\n",
    "\n",
    "# setup\n",
    "x1 = np.random.uniform(size=10**6)\n",
    "x2 = np.random.uniform(size=np.int64(100*CPUs/8)) # adjust the size of the problem\n",
    "x1_np = x1.reshape((1,x1.size))\n",
    "x2_np = x2.reshape((x2.size,1))\n",
    "\n",
    "# timing\n",
    "%timeit myfun_numpy_vec(x1_np,x2_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Numba:** The first call is slower, but the result is the same, and the subsequent calls are faster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.njit\n",
    "def myfun_numba(x1,x2):\n",
    "    y = np.empty(x1.size)\n",
    "    for i in range(x1.size):\n",
    "        if x1[i] < 0.5:\n",
    "            y[i] = np.sum(np.exp(x2*x1[i]))\n",
    "        else:\n",
    "            y[i] = np.sum(np.log(x2*x1[i]))\n",
    "    return y\n",
    "\n",
    "# call to just-in-time compile\n",
    "%time myfun_numba(x1,x2)\n",
    "\n",
    "# actual measurement\n",
    "%timeit myfun_numba(x1,x2)\n",
    "\n",
    "assert np.allclose(myfun_numpy_vec(x1_np,x2_np),myfun_numba(x1,x2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. <a id='toc2_'></a>[Further speed-up](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Further speed up:** Use\n",
    "\n",
    "1. parallelization (with ``prange``), and \n",
    "2. faster but less precise math (with ``fastmath``)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.njit(parallel=True)\n",
    "def myfun_numba_par(x1,x2):\n",
    "    y = np.empty(x1.size)\n",
    "    for i in nb.prange(x1.size): # in parallel across threads\n",
    "        if x1[i] < 0.5:\n",
    "            y[i] = np.sum(np.exp(x2*x1[i]))\n",
    "        else:\n",
    "            y[i] = np.sum(np.log(x2*x1[i]))\n",
    "    return y\n",
    "\n",
    "assert np.allclose(myfun_numpy_vec(x1_np,x2_np),myfun_numba_par(x1,x2))\n",
    "%timeit myfun_numba_par(x1,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.njit(parallel=True,fastmath=True)\n",
    "def myfun_numba_par_fast(x1,x2):\n",
    "    y = np.empty(x1.size)\n",
    "    for i in nb.prange(x1.size): # in parallel across threads\n",
    "        if x1[i] < 0.5:\n",
    "            y[i] = np.sum(np.exp(x2*x1[i]))\n",
    "        else:\n",
    "            y[i] = np.sum(np.log(x2*x1[i]))\n",
    "    return y\n",
    "\n",
    "assert np.allclose(myfun_numpy_vec(x1_np,x2_np),myfun_numba_par_fast(x1,x2))\n",
    "%timeit myfun_numba_par_fast(x1,x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Caveats:** Only a limited number of Python and Numpy features are supported inside just-in-time compiled functions.\n",
    "\n",
    "- [Supported Python features](https://numba.pydata.org/numba-doc/dev/reference/pysupported.html)\n",
    "- [Supported Numpy features](https://numba.pydata.org/numba-doc/dev/reference/numpysupported.html)\n",
    "\n",
    "**Parallization** can not always be used. Some problems are inherently sequential. If the result from a previous iteration of the loop is required in a later iteration, the cannot be executed seperately in parallel (except in some special cases such as summing). The larger the proportion of the code, which can be run in parallel is, the larger the potential speed-up is. This is called **Amdahl's Law**.\n",
    "\n",
    "<img src=\"https://github.com/NumEconCopenhagen/lectures-2019/raw/master/11/amdahls_law.png\" alt=\"amdahls_law\" width=40% />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10 | packaged by conda-forge | (main, Feb  1 2022, 21:22:07) [MSC v.1929 64 bit (AMD64)]"
  },
  "toc-autonumbering": true,
  "vscode": {
   "interpreter": {
    "hash": "47ef90cdf3004d3f859f1fb202523c65c07ba7c22eefd261b181f4744e2d0403"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
